<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Image Processing Project Deliverables</title>
    <!-- Load Tailwind CSS -->
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@100..900&display=swap" rel="stylesheet">
    <style>
        /* Custom font import and application */
        body {
            font-family: 'Inter', sans-serif;
        }
        /* Custom scrollbar for aesthetics */
        ::-webkit-scrollbar {
            width: 8px;
        }
        ::-webkit-scrollbar-thumb {
            background: #475569; /* Slate 600 */
            border-radius: 4px;
        }
        ::-webkit-scrollbar-thumb:hover {
            background: #64748b; /* Slate 500 */
        }
        
        /* === Custom styles for image zoom on hover === */
        .image-zoom-container {
            /* Ensures the element can be lifted above others and enables smooth transition */
            position: relative; 
            cursor: zoom-in;
            transition: transform 0.4s ease-in-out, box-shadow 0.4s ease-in-out;
            z-index: 10; /* Base Z-index */
        }

        .image-zoom-container:hover {
            /* Zoom in 2x and add a pronounced shadow */
            transform: scale(2.0); 
            box-shadow: 0 20px 40px rgba(0, 0, 0, 0.7);
            z-index: 50; /* Bring to front aggressively */
        }
        /* ============================================== */
    </style>
    <script>
        tailwind.config = {
            theme: {
                extend: {
                    colors: {
                        'background': '#0f172a', // Slate 900
                        'primary': '#334155',    // Slate 700
                        'accent': '#3b82f6',     // Blue 500
                    }
                }
            }
        }
    </script>
</head>
<body class="bg-background text-slate-300 min-h-screen">

    <header class="bg-primary shadow-lg p-6 sticky top-0 z-10">
        <div class="max-w-7xl mx-auto flex justify-between items-center">
            <!-- START: Button and Title Group -->
            <div class="flex items-center space-x-4">
                <a href="https://yuchenzhang789.github.io/index.html" class="px-3 py-1 bg-accent hover:bg-blue-600 text-white text-sm font-semibold rounded-lg transition duration-150 shadow-md">
                    ← Back to Main Webpage
                </a>
                <h1 class="text-3xl font-extrabold text-white">Project 2: Fun with Filters and Frequencies</h1>
            </div>
            <!-- END: Button and Title Group -->
            <p class="text-sm text-slate-400">Computer Vision Deliverables Showcase</p>
        </div>
    </header>

    <main class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-12 space-y-16">

        <!-- ==================================================================== -->
        <!-- SECTION 1: Part 1: Filters and Edges -->
        <!-- ==================================================================== -->
        <section class="bg-primary/50 p-8 rounded-xl shadow-2xl border-t-4 border-accent" id="part1">
            <h2 class="text-4xl font-bold mb-8 text-accent">Part 1: Filters and Edges</h2>

            <!-- 1.1 Convolution Implementation (RESTRUCTURED) -->
            <div class="mb-12 border-b border-slate-700 pb-8" id="part1-1">
                <h3 class="text-3xl font-bold mb-6 text-white border-b border-slate-600 pb-2">1.1. Convolution Implementations & Comparison</h3>
                <p class="mb-8">This section compares three convolution methods—a slow **4-loop** approach, a faster **2-loop** (optimized NumPy) method, and the highly optimized **Scipy built-in** function—across different types of kernels. The corresponding code implementations and analysis are provided in a separate subsection below.</p>

                <!-- 1.1.1 9x9 Box Filter -->
                <div class="mb-10 p-6 bg-slate-700/30 rounded-lg shadow-inner" id="filter-box">
                    <h4 class="text-2xl font-semibold mb-6 text-accent">1.1.1. 9x9 Box Filter (Smoothing) Results</h4>
                    
                    <div class="grid md:grid-cols-2 lg:grid-cols-3 gap-4">
                        <figure class="rounded-lg shadow-xl bg-primary image-zoom-container">
                            <img src="https://yuchenzhang789.github.io/proj_2/output/1_1_portrait2box9forloop_4.jpg" alt="Convolution result using 4 nested for loops for the box filter" class="w-full h-auto">
                            <figcaption class="p-3 text-center text-sm">Result: 4-Loop Implementation (11.457 seconds)</figcaption>
                        </figure>
                        <figure class="rounded-lg shadow-xl bg-primary image-zoom-container">
                            <img src="https://yuchenzhang789.github.io/proj_2/output/1_1_portrait2box9forloop_2.jpg" alt="Convolution result using 2 for loops and numpy slicing for the box filter" class="w-full h-auto">
                            <figcaption class="p-3 text-center text-sm">Result: 2-Loop Implementation (1.774 seconds)</figcaption>
                        </figure>
                        <figure class="rounded-lg shadow-xl bg-primary image-zoom-container">
                            <img src="https://yuchenzhang789.github.io/proj_2/output/1_1_portrait2box9scipy.jpg" alt="Convolution result using scipy.signal.convolve2d for the box filter" class="w-full h-auto">
                            <figcaption class="p-3 text-center text-sm">Result: Scipy Built-in (0.458 seconds)</figcaption>
                        </figure>
                    </div>

                    <!-- CONSOLIDATED SUMMARY BLOCK REMOVED FROM HERE -->
                </div>

                <!-- 1.1.2 Dx Filter -->
                <div class="mb-10 p-6 bg-slate-700/30 rounded-lg shadow-inner" id="filter-dx">
                    <h4 class="text-2xl font-semibold mb-6 text-accent">1.1.2. Dx Filter (Partial Derivative in X) Results</h4>
                    
                    <div class="grid md:grid-cols-2 lg:grid-cols-3 gap-4">
                        <figure class="rounded-lg shadow-xl bg-primary image-zoom-container">
                            <img src="https://yuchenzhang789.github.io/proj_2/output/1_1_portrait2dx9forloop_4.jpg" alt="Convolution result using 4 nested for loops for the Dx filter" class="w-full h-auto">
                            <figcaption class="p-3 text-center text-sm">Result: 4-Loop Implementation (0.688 seconds)</figcaption>
                        </figure>
                        <figure class="rounded-lg shadow-xl bg-primary image-zoom-container">
                            <img src="https://yuchenzhang789.github.io/proj_2/output/1_1_portrait2dx9forloop_2.jpg" alt="Convolution result using 2 for loops and numpy slicing for the Dx filter" class="w-full h-auto">
                            <figcaption class="p-3 text-center text-sm">Result: 2-Loop Implementation (0.905 seconds)</figcaption>
                        </figure>
                        <figure class="rounded-lg shadow-xl bg-primary image-zoom-container">
                            <img src="https://yuchenzhang789.github.io/proj_2/output/1_1_portrait2dx9scipy.jpg" alt="Convolution result using scipy.signal.convolve2d for the Dx filter" class="w-full h-auto">
                            <figcaption class="p-3 text-center text-sm">Result: Scipy Built-in (0.390 seconds)</figcaption>
                        </figure>
                    </div>
                </div>

                <!-- 1.1.3 Dy Filter -->
                <div class="mb-10 p-6 bg-slate-700/30 rounded-lg shadow-inner" id="filter-dy">
                    <h4 class="text-2xl font-semibold mb-6 text-accent">1.1.3. Dy Filter (Partial Derivative in Y) Results</h4>
                    
                    <div class="grid md:grid-cols-2 lg:grid-cols-3 gap-4">
                        <figure class="rounded-lg shadow-xl bg-primary image-zoom-container">
                            <img src="https://yuchenzhang789.github.io/proj_2/output/1_1_portrait2dy9forloop_4.jpg" alt="Convolution result using 4 nested for loops for the Dy filter" class="w-full h-auto">
                            <figcaption class="p-3 text-center text-sm">Result: 4-Loop Implementation (0.302 seconds)</figcaption>
                        </figure>
                        <figure class="rounded-lg shadow-xl bg-primary image-zoom-container">
                            <img src="https://yuchenzhang789.github.io/proj_2/output/1_1_portrait2dy9forloop_2.jpg" alt="Convolution result using 2 for loops and numpy slicing for the Dy filter" class="w-full h-auto">
                            <figcaption class="p-3 text-center text-sm">Result: 2-Loop Implementation (0.975 seconds)</figcaption>
                        </figure>
                        <figure class="rounded-lg shadow-xl bg-primary image-zoom-container">
                            <img src="https://yuchenzhang789.github.io/proj_2/output/1_1_portrait2dy9scipy.jpg" alt="Convolution result using scipy.signal.convolve2d for the Dy filter" class="w-full h-auto">
                            <figcaption class="p-3 text-center text-sm">Result: Scipy Built-in (0.423 seconds)</figcaption>
                        </figure>
                    </div>
                </div>
                
                <!-- 1.1.4 Code Snippets and Analysis (UPDATED SECTION) -->
                <div class="p-6 bg-slate-700/30 rounded-lg shadow-inner border-t border-slate-600" id="code-snippets">
                    <h4 class="text-2xl font-semibold mb-6 text-accent">1.1.4. Code Implementations, Runtime, and Boundary Analysis</h4>
                    
                    <!-- CONSOLIDATED SUMMARY BLOCK (MOVED HERE) -->
                    <div class="mt-2 p-4 bg-slate-800 rounded-lg">
                        <h5 class="text-xl font-medium text-slate-200 mb-2">Runtime and Boundary Analysis</h5>
                        <p class="text-sm">The runtime analysis across all kernel sizes (9x9 Box, Dx/Dy) established a clear performance hierarchy: the average runtime showed that the **4-loop method** was the **slowest** (e.g., $11.457s$ for 9x9), the **2-loop method** (using optimized NumPy slicing/strides) was significantly **faster** (e.g., $1.774s$ for 9x9), and the **Scipy Built-in** function was consistently the **fastest** (e.g., $0.458s$ for 9x9). We also observed that a **larger filter size**, such as the **9x9 box filter**, necessitates a much **longer runtime** compared to the smaller derivative filters. Functionally, all three methods produced identical results, confirming that the boundary conditions were robustly handled in all cases using **zero-padding** on the edge pixels.</p>
                    </div>
                    <!-- END CONSOLIDATED SUMMARY BLOCK -->

                    <h5 class="text-xl font-medium text-slate-200 mt-6 mb-4">Code Snippets Visualization</h5>
                    <p class="mb-4 text-sm text-slate-400">Screenshots of the Python code demonstrating the convolution function implementation using 4-loop, 2-loop, and Scipy.</p>
                    
                    <div class="grid md:grid-cols-3 gap-4">
                        <figure class="rounded-lg shadow-xl bg-primary border-4 border-slate-500 image-zoom-container">
                            <img src="https://yuchenzhang789.github.io/proj_2/output/1_1_code_forloop4.jpg" alt="Screenshot of the code snippet for the box filter implementation" class="w-full h-auto">
                            <figcaption class="p-3 text-center text-sm font-semibold text-sky-300">4 for loop Implementation</figcaption>
                        </figure>
                        <figure class="rounded-lg shadow-xl bg-primary border-4 border-slate-500 image-zoom-container">
                            <img src="https://yuchenzhang789.github.io/proj_2/output/1_1_code_forloop_2.jpg" alt="Screenshot of the code snippet for the Dx filter implementation" class="w-full h-auto">
                            <figcaption class="p-3 text-center text-sm font-semibold text-sky-300">2 for loop Implementation</figcaption>
                        </figure>
                        <figure class="rounded-lg shadow-xl bg-primary border-4 border-slate-500 image-zoom-container">
                            <img src="https://yuchenzhang789.github.io/proj_2/output/1_1_code_scipy.jpg" alt="Screenshot of the code snippet for the Dy filter implementation" class="w-full h-auto">
                            <figcaption class="p-3 text-center text-sm font-semibold text-sky-300">Built-in Scipy Implementation</figcaption>
                        </figure>
                    </div>
                </div>

            </div>

            <!-- 1.2 Partial Derivatives and Edges -->
            <div class="mb-12 border-b border-slate-700 pb-8" id="part1-2">
                <h3 class="text-2xl font-semibold mb-4 text-white">1.2. Partial Derivatives, Gradient, and Edges</h3>
                <p class="mb-6">Using finite difference filters (e.g., [-1, 0, 1]), we computed the image gradient, magnitude, and binarized edges.</p>
                
                <div class="grid md:grid-cols-2 lg:grid-cols-4 gap-4">
                    <figure class="rounded-lg shadow-xl bg-primary image-zoom-container">
                        <img src="https://yuchenzhang789.github.io/proj_2/output/1_2_cameraman_dx.jpg" alt="Partial derivative in X direction" class="w-full h-auto">
                        <figcaption class="p-3 text-center text-sm">Partial Derivative in x</figcaption>
                    </figure>
                    <figure class="rounded-lg shadow-xl bg-primary image-zoom-container">
                        <img src="https://yuchenzhang789.github.io/proj_2/output/1_2_cameraman_dy.jpg" alt="Partial derivative in Y direction" class="w-full h-auto">
                        <figcaption class="p-3 text-center text-sm">Partial Derivative in y</figcaption>
                    </figure>
                    <figure class="rounded-lg shadow-xl bg-primary image-zoom-container">
                        <img src="https://yuchenzhang789.github.io/proj_2/output/1_2_cameraman_gradient_magnitude.jpg" alt="Gradient Magnitude Image" class="w-full h-auto">
                        <figcaption class="p-3 text-center text-sm">Gradient Magnitude Image</figcaption>
                    </figure>
                    <figure class="rounded-lg shadow-xl bg-primary image-zoom-container">
                        <img src="https://yuchenzhang789.github.io/proj_2/output/1_2_cameraman_edge_map.jpg" alt="Binarized Edge Image" class="w-full h-auto">
                        <figcaption class="p-3 text-center text-sm">Binarized Edge Image (Thresholded = 0.31)</figcaption>
                    </figure>
                </div>

                <div class="mt-6 p-4 bg-slate-800 rounded-lg">
                    <h4 class="text-xl font-medium text-slate-200 mb-2">Edge Threshold Justification</h4>
                    <p class="text-sm">I chose a threshold of **0.31** for binarization. This value represents a minor tradeoff: it effectively removes background noise while still retaining important structural details in the cameraman's image.</p>
                </div>
            </div>

            <!-- 1.3 Gaussian and DoG Filters -->
            <div class="mb-12 border-b border-slate-700 pb-8" id="part1-3">
                <h3 class="text-2xl font-semibold mb-4 text-white">1.3. Gaussian and Difference of Gaussian (DoG) Filters</h3>
                <p class="mb-6">I constructed Gaussian filters using cv2.getGaussianKernel and built DoG filters by taking the deriavitives of the Gaussian filter. I set the sigma to be 1 and edge threshold as 0.28 to preserve details while removing noises.</p>

                <h4 class="text-xl font-medium text-slate-200 mb-4">Filter Visualizations and Applications ($\sigma=3$ for Gaussian, $\sigma_1=1, \sigma_2=5$ for DoG)</h4>
                <div class="grid md:grid-cols-3 gap-4">
                    <figure class="rounded-lg shadow-xl bg-primary image-zoom-container">
                        <!-- UPDATED URL for Gaussian Filter Visualization -->
                        <img src="https://yuchenzhang789.github.io/proj_2/output/1_3_gaussian_filter.jpg" alt="Visualization of the Gaussian Filter" class="w-full h-auto">
                        <figcaption class="p-3 text-center text-sm">Gaussian Filter Visualization</figcaption>
                    </figure>
                    <figure class="rounded-lg shadow-xl bg-primary image-zoom-container">
                        <!-- UPDATED URL for DoG Filter Visualization (using Dx component) -->
                        <img src="https://yuchenzhang789.github.io/proj_2/output/1_3_dog_x.jpg" alt="Visualization of the DoG Filter" class="w-full h-auto">
                        <figcaption class="p-3 text-center text-sm">DoG Filter Visualization (X Component)</figcaption>
                    </figure>
                    <figure class="rounded-lg shadow-xl bg-primary image-zoom-container">
                        <!-- UPDATED URL for DoG Filter Visualization (using Dx component) -->
                        <img src="https://yuchenzhang789.github.io/proj_2/output/1_3_dog_y.jpg" alt="Visualization of the DoG Filter" class="w-full h-auto">
                        <figcaption class="p-3 text-center text-sm">DoG Filter Visualization (Y Component)</figcaption>
                    </figure>
                    <figure class="rounded-lg shadow-xl bg-primary image-zoom-container">
                        <!-- UPDATED URL for Cameraman Smoothed (Gaussian) -->
                        <img src="https://yuchenzhang789.github.io/proj_2/output/1_3_cameraman_gaussian.jpg" alt="Cameraman smoothed with Gaussian" class="w-full h-auto">
                        <figcaption class="p-3 text-center text-sm">Cameraman Smoothed with Gaussian Filter</figcaption>
                    </figure>
                    <figure class="rounded-lg shadow-xl bg-primary image-zoom-container">
                        <!-- UPDATED URL for Cameraman Edges (DoG result) -->
                        <img src="https://yuchenzhang789.github.io/proj_2/output/1_3_cameraman_dog.jpg" alt="Cameraman edges detected with DoG" class="w-full h-auto">
                        <figcaption class="p-3 text-center text-sm">Cameraman Edges (One step approach)</figcaption>
                    </figure>
                    <figure class="rounded-lg shadow-xl bg-primary image-zoom-container">
                        <!-- UPDATED URL for Cameraman Edges (Finite Difference Comparison) -->
                        <img src="https://yuchenzhang789.github.io/proj_2/output/1_3_cameraman_edge_map.jpg" alt="Cameraman edges detected with Finite Difference" class="w-full h-auto">
                        <figcaption class="p-3 text-center text-sm">Cameraman Edges (Two step approach)</figcaption>
                    </figure>
                </div>
                <div class="mt-6 p-4 bg-slate-800 rounded-lg">
                    <h4 class="text-xl font-medium text-slate-200 mb-2">Comparison of Edge Detection</h4>
                    <p class="text-sm">The Finite Difference method is highly sensitive to noise, producing thick, noisy edges. The **DoG filter**, due to its band-pass nature, inherently incorporates smoothing, resulting in thinner, cleaner, and better localized edges.</p>
                    <p class="text-sm">In addition, I have shown the edge map created in two approaches: 1. One step approach: the image is convolved directly with DoG. 2. Two steps approach: the image in first convolved with Gaussian filter the computed the gradients to find the edges. The two resulted images are identical, proving the mathematical equvalence of two approaches.</p>
                </div>
            </div>

            <!-- 1.4 Bells and Whistles: Gradient Orientations -->
            <div id="part1-bw">
                <h3 class="text-2xl font-semibold mb-4 text-white border-b border-accent pb-2">Bells and Whistles: Gradient Orientations</h3>
                <p class="mb-6">I computed the gradient orientation for every pixel using the arctangent function without relying on built-in angle functions.</p>
                
                <div class="grid md:grid-cols-2 gap-4">
                    <figure class="rounded-lg shadow-xl bg-primary image-zoom-container">
                        <!-- UPDATED URL for Gradient Orientation Visualization -->
                        <img src="https://yuchenzhang789.github.io/proj_2/output/1_bw_cameraman_color_gradient.jpg" alt="Visualization of Gradient Orientations" class="w-full h-auto">
                        <figcaption class="p-3 text-center text-sm">Cameraman Gradient Orientation Map</figcaption>
                    </figure>
                    <div class="bg-slate-800 p-4 rounded-lg">
                        <h4 class="text-xl font-medium text-slate-200 mb-2">Process Explanation</h4>
                        <ul class="list-disc list-inside space-y-2 text-sm">
                            <li>Compute partial derivatives (dx, dy) in 2d space and use np.arctan2 to find the vector direction.</li>
                            <li>Implemente a hue by mapping the ratio of partial derivatives into an angle in the range [0, 2\pi)</li>
                            <li>Stack the hue with gradient magnitude to convert to rgb using skcolor.hsv2rgb to show the image in rgb channels.</li>
                        </ul>
                    </div>
                </div>
            </div>

        </section>

        <!-- ==================================================================== -->
        <!-- SECTION 2: Part 2: Applications -->
        <!-- ==================================================================== -->
        <section class="bg-primary/50 p-8 rounded-xl shadow-2xl border-t-4 border-accent" id="part2">
            <h2 class="text-4xl font-bold mb-8 text-accent">Part 2: Frequencies</h2>

            <!-- 2.1 Image Sharpening -->
            <div class="mb-12 border-b border-slate-700 pb-8" id="part2-1">
                <h3 class="text-2xl font-semibold mb-4 text-white">2.1. Image Sharpening</h3>
                <p class="mb-4">This works by generating a high-frequency detail layer (the 'mask') and adding it back to the original image. The process is:</p>
                <div class="bg-slate-800 p-4 rounded-lg mb-6">
                    <code class="block text-accent font-mono text-sm">Sharpened = Original + alpha * (Original - Blurred)</code>
                </div>
                <p class="mb-6">The blurred version is obtained via applying a Gaussian filter, which removes high frequencies. Subtracting the blurred image from the original isolates the high-frequency components. Multiplying this by the amplification factor alpha to control the sharpening intensity.</p>

                <h4 class="text-xl font-medium text-slate-200 mb-4">Taj Mahal Example (alpha=1.0)</h4>
                <div class="grid md:grid-cols-4 gap-4">
                    <figure class="rounded-lg overflow-hidden shadow-xl bg-primary">
                        <img src="https://yuchenzhang789.github.io/proj_2/data/taj.jpg" alt="Original Taj Mahal" class="w-full h-auto">
                        <figcaption class="p-3 text-center text-sm">Original Image</figcaption>
                    </figure>
                    <figure class="rounded-lg overflow-hidden shadow-xl bg-primary">
                        <img src="https://yuchenzhang789.github.io/proj_2/output/2_1_taj_blurred.jpg" alt="Blurred Taj Mahal" class="w-full h-auto">
                        <figcaption class="p-3 text-center text-sm">Blurred</figcaption>
                    </figure>
                    <figure class="rounded-lg overflow-hidden shadow-xl bg-primary">
                        <img src="https://yuchenzhang789.github.io/proj_2/output/2_1_taj_high_freq.jpg" alt="High frequency mask of Taj Mahal" class="w-full h-auto">
                        <figcaption class="p-3 text-center text-sm">High-Frequency</figcaption>
                    </figure>
                    <figure class="rounded-lg overflow-hidden shadow-xl bg-primary">
                        <img src="https://yuchenzhang789.github.io/proj_2/output/2_1_taj_sharped.jpg" alt="Sharpened Taj Mahal" class="w-full h-auto">
                        <figcaption class="p-3 text-center text-sm">Sharpened</figcaption>
                    </figure>
                </div>
                
                <h4 class="text-xl font-medium text-slate-200 mt-8 mb-4">Berkeley Example (alpha=1.0)</h4>
                <div class="grid md:grid-cols-4 gap-4">
                    <figure class="rounded-lg overflow-hidden shadow-xl bg-primary">
                        <img src="https://yuchenzhang789.github.io/proj_2/data/berkeley.jpg" alt="Original Taj Mahal" class="w-full h-auto">
                        <figcaption class="p-3 text-center text-sm">Original Image</figcaption>
                    </figure>
                    <figure class="rounded-lg overflow-hidden shadow-xl bg-primary">
                        <img src="https://yuchenzhang789.github.io/proj_2/output/2_1_berkeley_blurred.jpg" alt="Blurred Taj Mahal" class="w-full h-auto">
                        <figcaption class="p-3 text-center text-sm">Blurred</figcaption>
                    </figure>
                    <figure class="rounded-lg overflow-hidden shadow-xl bg-primary">
                        <img src="https://yuchenzhang789.github.io/proj_2/output/2_1_berkeley_high_freq.jpg" alt="High frequency mask of Taj Mahal" class="w-full h-auto">
                        <figcaption class="p-3 text-center text-sm">High-Frequency</figcaption>
                    </figure>
                    <figure class="rounded-lg overflow-hidden shadow-xl bg-primary">
                        <img src="https://yuchenzhang789.github.io/proj_2/output/2_1_berkeley_sharped.jpg" alt="Sharpened Taj Mahal" class="w-full h-auto">
                        <figcaption class="p-3 text-center text-sm">Sharpened</figcaption>
                    </figure>
                </div>

                <!-- START: New Custom Image Set 2 -->
                <h4 class="text-xl font-medium text-slate-200 mt-8 mb-4">Varying Sharpening Amount (alpha)</h4>
                <div class="grid md:grid-cols-4 gap-4">
                    <figure class="rounded-lg overflow-hidden shadow-xl bg-primary">
                        <img src="https://yuchenzhang789.github.io/proj_2/output/2_1_taj_sharped_0.5.jpg" alt="Original Taj Mahal" class="w-full h-auto">
                        <figcaption class="p-3 text-center text-sm">Alpha = 0.5</figcaption>
                    </figure>
                    <figure class="rounded-lg overflow-hidden shadow-xl bg-primary">
                        <img src="https://yuchenzhang789.github.io/proj_2/output/2_1_taj_sharped.jpg" alt="Blurred Taj Mahal" class="w-full h-auto">
                        <figcaption class="p-3 text-center text-sm">Alpha = 1.0</figcaption>
                    </figure>
                    <figure class="rounded-lg overflow-hidden shadow-xl bg-primary">
                        <img src="https://yuchenzhang789.github.io/proj_2/output/2_1_taj_sharped_3.jpg" alt="High frequency mask of Taj Mahal" class="w-full h-auto">
                        <figcaption class="p-3 text-center text-sm">Alpha = 3.0</figcaption>
                    </figure>
                    <figure class="rounded-lg overflow-hidden shadow-xl bg-primary">
                        <img src="https://yuchenzhang789.github.io/proj_2/output/2_1_taj_sharped_6.jpg" alt="Sharpened Taj Mahal" class="w-full h-auto">
                        <figcaption class="p-3 text-center text-sm">Alpha = 6.0</figcaption>
                    </figure>
                </div>
                <!-- END: New Custom Image Set 2 -->
            </div>

            <!-- 2.2 Hybrid Images -->
            <div class="mb-12 border-b border-slate-700 pb-8" id="part2-2">
                <h3 class="text-2xl font-semibold mb-4 text-white">2.2. Hybrid Images (Blending High and Low Frequencies)</h3>
                <p class="mb-6">Hybrid images are created by blending the high spatial frequencies of one image with the low spatial frequencies of another. This allows the perception to shift based on viewing distance.</p>

                <h4 class="text-xl font-medium text-slate-200 mb-4">Hybrid 1: DerekPicture (High-Pass) + Nutmeg (Low-Pass) Process</h4>
                
                <!-- START UPDATED FULL PROCESS VISUALIZATION -->
                <div class="bg-slate-800 p-4 rounded-lg mb-6">
                    <h5 class="text-lg font-medium text-slate-200 mb-4 border-b border-slate-600 pb-2">Full Process Visualization (sigma_1=9, sigma_2=15)</h5>
                    <div class="grid grid-cols-2 sm:grid-cols-4 gap-4">
                        <!-- Row 1: Inputs and Initial Processing -->
                        <figure class="rounded-lg overflow-hidden shadow-xl bg-primary">
                            <img src="https://yuchenzhang789.github.io/proj_2/data/nutmeg.jpg" alt="Original Derek Picture" class="w-full h-auto">
                            <figcaption class="p-2 text-center text-xs">Original 1 (High-Pass)</figcaption>
                        </figure>
                        <figure class="rounded-lg overflow-hidden shadow-xl bg-primary">
                            <img src="https://yuchenzhang789.github.io/proj_2/data/DerekPicture.jpg" alt="Original Nutmeg Picture" class="w-full h-auto">
                            <figcaption class="p-2 text-center text-xs">Original 2 (Low-Pass)</figcaption>
                        </figure>
                        <figure class="rounded-lg overflow-hidden shadow-xl bg-primary">
                            <img src="https://yuchenzhang789.github.io/proj_2/output/2_2_fourier_img1_fft.jpg" alt="Fourier Transform of Original 1" class="w-full h-auto">
                            <figcaption class="p-2 text-center text-xs">FT: Image 1</figcaption>
                        </figure>
                        <figure class="rounded-lg overflow-hidden shadow-xl bg-primary">
                            <img src="https://yuchenzhang789.github.io/proj_2/output/2_2_fourier_img2_fft.jpg" alt="Fourier Transform of Original 2" class="w-full h-auto">
                            <figcaption class="p-2 text-center text-xs">FT: Image 2</figcaption>
                        </figure>

                        <!-- Row 2: Filtered Results and Final Output -->
                        <figure class="rounded-lg overflow-hidden shadow-xl bg-primary">
                            <img src="https://yuchenzhang789.github.io/proj_2/output/2_2_fourier_im1_high_fft.jpg" alt="High-Pass filtered Derek" class="w-full h-auto">
                            <figcaption class="p-2 text-center text-xs">Filtered 1 (High-Pass)</figcaption>
                        </figure>
                        <figure class="rounded-lg overflow-hidden shadow-xl bg-primary">
                            <img src="https://yuchenzhang789.github.io/proj_2/output/2_2_fourier_im2_low_fft.jpg" alt="Low-Pass filtered Nutmeg" class="w-full h-auto">
                            <figcaption class="p-2 text-center text-xs">Filtered 2 (Low-Pass)</figcaption>
                        </figure>
                        <figure class="rounded-lg overflow-hidden shadow-xl bg-primary">
                            <img src="https://yuchenzhang789.github.io/proj_2/output/2_2_fourier_hybrid_fft.jpg" alt="Fourier Transform of the Hybrid Image" class="w-full h-auto">
                            <figcaption class="p-2 text-center text-xs">FT: Final Hybrid</figcaption>
                        </figure>
                        <figure class="rounded-lg overflow-hidden shadow-xl bg-primary border-2 border-accent">
                            <img src="https://yuchenzhang789.github.io/proj_2/output/2_2_nutmeg_DerekPicture_hybrid.jpg" alt="Final Hybrid Image" class="w-full h-auto">
                            <figcaption class="p-2 text-center text-xs font-bold text-accent">FINAL HYBRID</figcaption>
                        </figure>
                    </div>

                    <!-- Cutoff Choice Justification (NEW) -->
                    <div class="mt-4 p-3 bg-slate-700/50 rounded-lg">
                        <h6 class="text-sm font-semibold text-slate-300 mb-1">Cutoff Frequency Justification</h6>
                        <p class="text-xs text-slate-400">The cutoff frequencies were set to sigma_1 = 9 (for high-pass Nutmeg) and sigma_2 = 15 (for low-pass Derek). These values were chosen empirically. sigma_1 needs to be small enough to ensure the cat's low-frequency components are removed so the image is nearly invisible from afar. sigma_2 must be large enough to retain sufficient low-frequency detail of Derek for it to be visible from a distance, while its high frequencies are fully removed to avoid blurring interference when viewed up close.</p>
                    </div>
                </div>
                <!-- END UPDATED FULL PROCESS VISUALIZATION -->

                <h4 class="text-xl font-medium text-slate-200 mb-4">Custom Hybrid Images</h4>
                <div class="grid md:grid-cols-2 gap-8">
                    <!-- Hybrid 2 -->
                    <div class="space-y-3 bg-slate-800 p-4 rounded-lg">
                        <h5 class="text-lg font-medium text-slate-200">Hybrid 2: Cat + Selfie (sigma_1=9, sigma_2=15)</h5>
                        <div class="grid grid-cols-3 gap-2">
                            <figure class="overflow-hidden rounded-md">
                                <img src="https://yuchenzhang789.github.io/proj_2/data/toro.jpg" alt="Original Cat" class="w-full h-auto">
                            </figure>
                            <figure class="overflow-hidden rounded-md">
                                <img src="https://yuchenzhang789.github.io/proj_2/data/selfie.jpg" alt="Original Dog" class="w-full h-auto">
                            </figure>
                            <figure class="overflow-hidden rounded-md border-2 border-accent">
                                <img src="https://yuchenzhang789.github.io/proj_2/output/2_2_toro_selfie_hybrid_color_gray.jpg" alt="Hybrid CatDog Image" class="w-full h-auto">
                            </figure>
                        </div>
                    </div>
                    <!-- Hybrid 3 -->
                    <div class="space-y-3 bg-slate-800 p-4 rounded-lg">
                        <h5 class="text-lg font-medium text-slate-200">Hybrid 3: Labubu + Actor (sigma_1=7, sigma_2=12)</h5>
                        <div class="grid grid-cols-3 gap-2">
                            <figure class="overflow-hidden rounded-md">
                                <img src="https://yuchenzhang789.github.io/proj_2/data/labubu.jpg" alt="Original Bird" class="w-full h-auto">
                            </figure>
                            <figure class="overflow-hidden rounded-md">
                                <img src="https://yuchenzhang789.github.io/proj_2/data/portrait2.jpg" alt="Original Plane" class="w-full h-auto">
                            </figure>
                            <figure class="overflow-hidden rounded-md border-2 border-accent">
                                <img src="https://yuchenzhang789.github.io/proj_2/output/2_2_labubu_portrait2_hybrid_2.jpg" alt="Hybrid PlaneBird Image" class="w-full h-auto">
                            </figure>
                        </div>
                    </div>
                </div>
                
                <!-- Bells and Whistles: Color Exploration (UPDATED) -->
                <div class="mt-6 p-4 bg-slate-900 rounded-lg border border-slate-700">
                    <h4 class="text-xl font-medium text-accent mb-4">Bells and Whistles: Color Exploration in Hybrid Images</h4>

                    <h5 class="text-lg font-medium text-slate-200 mb-3">Color Combinations</h5>
                    <div class="grid grid-cols-2 lg:grid-cols-4 gap-4">
                        <!-- Gray-Gray -->
                        <figure class="rounded-lg overflow-hidden shadow-xl bg-primary">
                            <img src="https://yuchenzhang789.github.io/proj_2/output/2_2_toro_selfie_hybrid_gray_gray.jpg" alt="Hybrid image combining two grayscale images" class="w-full h-auto">
                            <figcaption class="p-2 text-center text-xs">Gray (High) + Gray (Low)</figcaption>
                        </figure>
                        <!-- Gray-Color -->
                        <figure class="rounded-lg overflow-hidden shadow-xl bg-primary">
                            <img src="https://yuchenzhang789.github.io/proj_2/output/2_2_toro_selfie_hybrid_color_gray.jpg" alt="Hybrid image combining grayscale high-pass with color low-pass" class="w-full h-auto">
                            <figcaption class="p-2 text-center text-xs">Gray (High) + Color (Low)</figcaption>
                        </figure>
                        <!-- Color-Gray -->
                        <figure class="rounded-lg overflow-hidden shadow-xl bg-primary">
                            <img src="https://yuchenzhang789.github.io/proj_2/output/2_2_toro_selfie_hybrid_gray_color.jpg" alt="Hybrid image combining color high-pass with grayscale low-pass" class="w-full h-auto">
                            <figcaption class="p-2 text-center text-xs">Color (High) + Gray (Low)</figcaption>
                        </figure>
                        <!-- Color-Color -->
                        <figure class="rounded-lg overflow-hidden shadow-xl bg-primary">
                            <img src="https://yuchenzhang789.github.io/proj_2/output/2_2_toro_selfie_hybrid_color_color.jpg" alt="Hybrid image combining two color images" class="w-full h-auto">
                            <figcaption class="p-2 text-center text-xs">Color (High) + Color (Low)</figcaption>
                        </figure>
                    </div>

                    <div class="mt-6 p-4 bg-slate-800 rounded-lg">
                        <h5 class="text-lg font-medium text-slate-200 mb-2">Analysis of Color Blending</h5>
                        <ul class="list-disc list-inside space-y-2 text-sm text-slate-400">
                            <li><strong>Gray + Gray:</strong> This yields a purely luminance-based hybrid. The perceptual shift is solely dependent on spatial frequency and viewing distance, offering a clean, traditional result.</li>
                            <li><strong>Gray + Color (Low-Pass):</strong> This provides the BEST perceptual result. The color of the low-frequency image (visible from afar) dominates the distant view, while the high-frequency image (seen up close) is perceived clearly in black and white, avoiding confusing chromatic fringing.</li>
                            <li><strong>Color (High-Pass) + Gray:</strong> Up close, the high-frequency image is seen in color, but from a distance, the gray low-frequency image loses its visual impact, making the distant perception less engaging.</li>
                            <li><strong>Color + Color:</strong> The color in this hybrid is slightly off. When viewed from afar, the high-frequency image's color channels interfere with the low-frequency image, leading to messy, indistinct colors or blurry edges when the eye tries to fuse the two.</li>
                        </ul>
                    </div>
                </div>
            </div>

            <!-- 2.3 + 2.4 Multi-resolution Blending (MODIFIED SECTION) -->
            <div id="part2-3-4">
                <h3 class="text-2xl font-semibold mb-4 text-white">2.3 + 2.4. Multi-resolution Blending</h3>
                <p class="mb-6">Multi-resolution blending uses Gaussian/Laplacian stacks to decompose input images, and a Gaussian stack of a mask to blend the images at each frequency level, resulting in a seamless composite image.</p>

                <!-- Gaussian Stacks Visualization (8 images in 4x2) -->
                <h4 class="text-xl font-medium text-slate-200 mb-4">Gaussian Stacks (Orange and Apple)</h4>
                <p class="mb-4 text-sm text-slate-400">The Gaussian stacks show the image at progressively lower spatial frequencies .</p>
                <div class="grid grid-cols-4 gap-4 mb-8">
                    <!-- Orange Gaussian Stack -->
                    <figure class="rounded-lg overflow-hidden shadow-xl bg-primary">
                        <img src="https://yuchenzhang789.github.io/proj_2/output/2_3_apple_gaussian_level_0.jpg" alt="Apple Original" class="w-full h-auto">
                        <figcaption class="p-1 text-center text-xs">Apple Gaussian Stack Level 0</figcaption>
                    </figure>
                    <figure class="rounded-lg overflow-hidden shadow-xl bg-primary">
                        <img src="https://yuchenzhang789.github.io/proj_2/output/2_3_apple_gaussian_level_1.jpg" alt="Apple Gaussian Stack Level 0" class="w-full h-auto">
                        <figcaption class="p-1 text-center text-xs">Apple Gaussian Stack Level 1</figcaption>
                    </figure>
                    <figure class="rounded-lg overflow-hidden shadow-xl bg-primary">
                        <img src="https://yuchenzhang789.github.io/proj_2/output/2_3_apple_gaussian_level_2.jpg" alt="Apple Gaussian Stack Level 1" class="w-full h-auto">
                        <figcaption class="p-1 text-center text-xs">Apple Gaussian Stack Level 2</figcaption>
                    </figure>
                    <figure class="rounded-lg overflow-hidden shadow-xl bg-primary">
                        <img src="https://yuchenzhang789.github.io/proj_2/output/2_3_apple_gaussian_level_3.jpg" alt="Apple Gaussian Stack Level 2" class="w-full h-auto">
                        <figcaption class="p-1 text-center text-xs">Apple Gaussian Stack Level 3</figcaption>
                    </figure>
                    
                    <!-- Apple Gaussian Stack -->
                    <figure class="rounded-lg overflow-hidden shadow-xl bg-primary">
                        <img src="https://yuchenzhang789.github.io/proj_2/output/2_3_orange_gaussian_level_0.jpg" alt="Orange Original" class="w-full h-auto">
                        <figcaption class="p-1 text-center text-xs">Orange Gaussian Stack Level 0</figcaption>
                    </figure>
                    <figure class="rounded-lg overflow-hidden shadow-xl bg-primary">
                        <img src="https://yuchenzhang789.github.io/proj_2/output/2_3_orange_gaussian_level_1.jpg" alt="Orange Gaussian Stack Level 0" class="w-full h-auto">
                        <figcaption class="p-1 text-center text-xs">Orange Gaussian Stack Level 1</figcaption>
                    </figure>
                    <figure class="rounded-lg overflow-hidden shadow-xl bg-primary">
                        <img src="https://yuchenzhang789.github.io/proj_2/output/2_3_orange_gaussian_level_2.jpg" alt="Orange Gaussian Stack Level 1" class="w-full h-auto">
                        <figcaption class="p-1 text-center text-xs">Orange Gaussian Stack Level 2</figcaption>
                    </figure>
                    <figure class="rounded-lg overflow-hidden shadow-xl bg-primary">
                        <img src="https://yuchenzhang789.github.io/proj_2/output/2_3_orange_gaussian_level_3.jpg" alt="Orange Gaussian Stack Level 2" class="w-full h-auto">
                        <figcaption class="p-1 text-center text-xs">Orange Gaussian Stack Level 3</figcaption>
                    </figure>
                </div>
                <!-- END: Gaussian Stacks Visualization -->
                
                <!-- Laplacian Stacks Visualization (12 images in 4x3) -->
                <h4 class="text-xl font-medium text-slate-200 mb-4">Laplacian Stacks and Blended Result ($N=4$ levels)</h4>
                <p class="mb-4 text-sm text-slate-400">The images below show the Laplacian stack for Apple, the Laplacian stack for Orange, and the resulting Blended Laplacian stack, from the highest frequency (L0) down to the lowest (L3).</p>
                <div class="grid grid-cols-3 gap-4 mb-8">
                    <!-- Headers -->
                    <div class="text-center font-bold text-slate-400 border-b pb-2">Apple Laplacian</div>
                    <div class="text-center font-bold text-slate-400 border-b pb-2">Orange Laplacian</div>
                    <div class="text-center font-bold text-slate-400 border-b pb-2">Blended Laplacian</div>

                    <!-- Level 0 (Highest Frequency) -->
                    <figure class="rounded-lg overflow-hidden shadow-xl bg-primary">
                        <img src="https://yuchenzhang789.github.io/proj_2/output/2_3_apple_laplacian_level_0.jpg" alt="Apple Laplacian Stack Level 0" class="w-full h-auto">
                        <figcaption class="p-1 text-center text-xs">L0</figcaption>
                    </figure>
                    <figure class="rounded-lg overflow-hidden shadow-xl bg-primary">
                        <img src="https://yuchenzhang789.github.io/proj_2/output/2_3_orange_laplacian_level_0.jpg" alt="Orange Laplacian Stack Level 0" class="w-full h-auto">
                        <figcaption class="p-1 text-center text-xs">L0</figcaption>
                    </figure>
                    <figure class="rounded-lg overflow-hidden shadow-xl bg-primary">
                        <img src="https://yuchenzhang789.github.io/proj_2/output/2_4_apple_orange_hybrid_level_0.jpg" alt="Blended Laplacian Stack Level 0" class="w-full h-auto">
                        <figcaption class="p-1 text-center text-xs">L0 Blended</figcaption>
                    </figure>

                    <!-- Level 1 -->
                    <figure class="rounded-lg overflow-hidden shadow-xl bg-primary">
                        <img src="https://yuchenzhang789.github.io/proj_2/output/2_3_apple_laplacian_level_1.jpg" alt="Apple Laplacian Stack Level 1" class="w-full h-auto">
                        <figcaption class="p-1 text-center text-xs">L1</figcaption>
                    </figure>
                    <figure class="rounded-lg overflow-hidden shadow-xl bg-primary">
                        <img src="https://yuchenzhang789.github.io/proj_2/output/2_3_orange_laplacian_level_1.jpg" alt="Orange Laplacian Stack Level 1" class="w-full h-auto">
                        <figcaption class="p-1 text-center text-xs">L1</figcaption>
                    </figure>
                    <figure class="rounded-lg overflow-hidden shadow-xl bg-primary">
                        <img src="https://yuchenzhang789.github.io/proj_2/output/2_4_apple_orange_hybrid_level_1.jpg" alt="Blended Laplacian Stack Level 1" class="w-full h-auto">
                        <figcaption class="p-1 text-center text-xs">L1 Blended</figcaption>
                    </figure>

                    <!-- Level 2 -->
                    <figure class="rounded-lg overflow-hidden shadow-xl bg-primary">
                        <img src="https://yuchenzhang789.github.io/proj_2/output/2_3_apple_laplacian_level_2.jpg" alt="Apple Laplacian Stack Level 2" class="w-full h-auto">
                        <figcaption class="p-1 text-center text-xs">L2</figcaption>
                    </figure>
                    <figure class="rounded-lg overflow-hidden shadow-xl bg-primary">
                        <img src="https://yuchenzhang789.github.io/proj_2/output/2_3_orange_laplacian_level_2.jpg" alt="Orange Laplacian Stack Level 2" class="w-full h-auto">
                        <figcaption class="p-1 text-center text-xs">L2</figcaption>
                    </figure>
                    <figure class="rounded-lg overflow-hidden shadow-xl bg-primary">
                        <img src="https://yuchenzhang789.github.io/proj_2/output/2_4_apple_orange_hybrid_level_2.jpg" alt="Blended Laplacian Stack Level 2" class="w-full h-auto">
                        <figcaption class="p-1 text-center text-xs">L2 Blended</figcaption>
                    </figure>

                    <!-- Level 3 (Lowest Frequency) -->
                    <figure class="rounded-lg overflow-hidden shadow-xl bg-primary">
                        <img src="https://yuchenzhang789.github.io/proj_2/output/2_3_apple_gaussian_original_masked.jpg" alt="Apple Laplacian Stack Level 3" class="w-full h-auto">
                        <figcaption class="p-1 text-center text-xs">L3</figcaption>
                    </figure>
                    <figure class="rounded-lg overflow-hidden shadow-xl bg-primary">
                        <img src="https://yuchenzhang789.github.io/proj_2/output/2_3_orange_gaussian_original_masked.jpg" alt="Orange Laplacian Stack Level 3" class="w-full h-auto">
                        <figcaption class="p-1 text-center text-xs">L3</figcaption>
                    </figure>
                    <figure class="rounded-lg overflow-hidden shadow-xl bg-primary">
                        <img src="https://yuchenzhang789.github.io/proj_2/output/2_4_apple_orange_hybrid_blend.jpg" alt="Blended Laplacian Stack Level 3" class="w-full h-auto">
                        <figcaption class="p-1 text-center text-xs">L3 Blended</figcaption>
                    </figure>
                </div>
                <!-- END: Laplacian Stacks Visualization (12 images) -->

                <!-- START: Bells and Whistles - Irregular Mask Illustration -->
                <h4 class="text-xl font-medium text-slate-200 mt-8 mb-4 border-b border-slate-600 pb-2">Bells and Whistles: Irregular Mask Blending (The Eye-Mouth Blend)</h4>
                <p class="mb-4 text-sm text-slate-400">Multi-resolution blending use a irregular, circular mask to create different effect.</p>
                <div class="grid grid-cols-5 gap-4 mb-8">
                    <!-- Headers -->
                    <div class="text-center font-bold text-slate-400 border-b pb-2 col-span-1">The Mask</div>
                    <div class="text-center font-bold text-slate-400 border-b pb-2 col-span-1">Laplacian Stack Level 0</div>
                    <div class="text-center font-bold text-slate-400 border-b pb-2 col-span-1">Laplacian Stack Level 1</div>
                    <div class="text-center font-bold text-slate-400 border-b pb-2 col-span-1">Laplacian Stack Level 2</div>
                    <div class="text-center font-bold text-slate-400 border-b pb-2 col-span-1">Laplacian Stack Level 3</div>
                    
                    <figure class="rounded-lg overflow-hidden shadow-xl bg-primary">
                        <img src="https://yuchenzhang789.github.io/proj_2/data/mask3.jpg" alt="Input image 1: an eye" class="w-full h-auto">
                        <figcaption class="p-1 text-center text-xs">The Eye</figcaption>
                    </figure>
                    <figure class="rounded-lg overflow-hidden shadow-xl bg-primary">
                        <img src="https://yuchenzhang789.github.io/proj_2/output/2_4_apple_orange_hybrid_level_0_irregular_mask.jpg" alt="Input image 2: a face with a mouth" class="w-full h-auto">
                        <figcaption class="p-1 text-center text-xs">The Face</figcaption>
                    </figure>
                    <figure class="rounded-lg overflow-hidden shadow-xl bg-primary">
                        <img src="https://yuchenzhang789.github.io/proj_2/output/2_4_apple_orange_hybrid_level_1_irregular_mask.jpg" alt="Visualization of the irregular mask used for blending" class="w-full h-auto">
                        <figcaption class="p-1 text-center text-xs">The Irregular Mask</figcaption>
                    </figure>
                    <figure class="rounded-lg overflow-hidden shadow-xl bg-primary">
                        <img src="https://yuchenzhang789.github.io/proj_2/output/2_4_apple_orange_hybrid_level_2_irregular_mask.jpg" alt="Result of a simple cut and paste without blending" class="w-full h-auto">
                        <figcaption class="p-1 text-center text-xs">Cut/Paste Artifact</figcaption>
                    </figure>
                    <figure class="rounded-lg overflow-hidden shadow-xl bg-primary border-2 border-accent">
                        <img src="https://yuchenzhang789.github.io/proj_2/output/2_4_apple_orange_hybrid_blend_irregular_mask.jpg" alt="Final blended result using the irregular mask" class="w-full h-auto">
                        <figcaption class="p-1 text-center text-xs font-bold text-accent">Final Seamless Blend</figcaption>
                    </figure>
                </div>
                <!-- END: Bells and Whistles - Irregular Mask Illustration -->


                <!-- START: Final Blended Results (6 images in 2x3 matrix) -->
                <h4 class="text-xl font-medium text-slate-200 mb-4">Custom Blended Photo Sets (2 Set of images)</h4>
                <p class="mb-4 text-sm text-slate-400">Two custom image pairs blended using a multi-resolution approach. Each row shows Input A, Input B, and the Final Blended Result.</p>
                <div class="grid grid-cols-3 gap-4 mb-8">
                    
                    <!-- Headers for the blend section -->
                    <div class="text-center font-bold text-slate-400 border-b pb-2">Input A</div>
                    <div class="text-center font-bold text-slate-400 border-b pb-2">Input B</div>
                    <div class="text-center font-bold text-slate-400 border-b pb-2">Final Blend Result</div>
                    
                    <!-- Row 2: Custom Blend Set 1 -->
                    <figure class="rounded-lg overflow-hidden shadow-xl bg-primary">
                        <img src="https://yuchenzhang789.github.io/proj_2/data/f1_car2.jpg" alt="Custom set 1 Input A" class="w-full h-auto">
                        <figcaption class="p-1 text-center text-xs">F1 Car 1</figcaption>
                    </figure>
                    <figure class="rounded-lg overflow-hidden shadow-xl bg-primary">
                        <img src="https://yuchenzhang789.github.io/proj_2/data/f1_car4.jpg" alt="Custom set 1 Input B" class="w-full h-auto">
                        <figcaption class="p-1 text-center text-xs">F1 car 2</figcaption>
                    </figure>
                    <figure class="rounded-lg overflow-hidden shadow-xl bg-primary border-2 border-accent">
                        <img src="https://yuchenzhang789.github.io/proj_2/output/2_4_f1_car2_f1_car4_hybrid_blend.jpg" alt="Custom set 1 Blended Result" class="w-full h-auto">
                        <figcaption class="p-1 text-center text-xs font-bold text-accent">Blend of F1 cars</figcaption>
                    </figure>

                    <!-- Row 3: Custom Blend Set 2 -->
                    <figure class="rounded-lg overflow-hidden shadow-xl bg-primary">
                        <img src="https://yuchenzhang789.github.io/proj_2/data/labubu2.jpg" alt="Custom set 2 Input A" class="w-full h-auto">
                        <figcaption class="p-1 text-center text-xs">Labubu 1</figcaption>
                    </figure>
                    <figure class="rounded-lg overflow-hidden shadow-xl bg-primary">
                        <img src="https://yuchenzhang789.github.io/proj_2/data/labubu3.jpg" alt="Custom set 2 Input B" class="w-full h-auto">
                        <figcaption class="p-1 text-center text-xs">Labubu 2</figcaption>
                    </figure>
                    <figure class="rounded-lg overflow-hidden shadow-xl bg-primary border-2 border-accent">
                        <img src="https://yuchenzhang789.github.io/proj_2/output/2_4_labubu2_labubu3_hybrid_blend.jpg" alt="Custom set 2 Blended Result" class="w-full h-auto">
                        <figcaption class="p-1 text-center text-xs font-bold text-accent">Blend of Labubus</figcaption>
                    </figure>

                </div>
                <!-- END: Final Blended Results -->
                
                <!-- START: Bells and Whistles - Additional Color Explorations  -->
                <h4 class="text-xl font-medium text-slate-200 mt-8 mb-4 border-b border-slate-600 pb-2">Bells and Whistles: Additional Color Explorations</h4>
                <div class="grid grid-cols-2 md:grid-cols-4 gap-4 mb-8">
                    <figure class="rounded-lg overflow-hidden shadow-xl bg-primary">
                        <img src="https://yuchenzhang789.github.io/proj_2/output/2_4_apple_orange_hybrid_blend_gray_gray.jpg" alt="Custom mask design used for blending" class="w-full h-auto">
                        <figcaption class="p-2 text-center text-sm">Gray + Gray</figcaption>
                    </figure>
                    <figure class="rounded-lg overflow-hidden shadow-xl bg-primary">
                        <img src="https://yuchenzhang789.github.io/proj_2/output/2_4_apple_orange_hybrid_blend_gray_color.jpg" alt="Blend result using a different sigma value" class="w-full h-auto">
                        <figcaption class="p-2 text-center text-sm">Gray + Color</figcaption>
                    </figure>
                    <figure class="rounded-lg overflow-hidden shadow-xl bg-primary">
                        <img src="https://yuchenzhang789.github.io/proj_2/output/2_4_apple_orange_hybrid_blend_color_gray.jpg" alt="Blend result with just low frequency layer" class="w-full h-auto">
                        <figcaption class="p-2 text-center text-sm">Color + Gray</figcaption>
                    </figure>
                    <figure class="rounded-lg overflow-hidden shadow-xl bg-primary">
                        <img src="https://yuchenzhang789.github.io/proj_2/output/2_4_apple_orange_hybrid_blend.jpg" alt="Blending of two grayscale images" class="w-full h-auto">
                        <figcaption class="p-2 text-center text-sm">Color + Color</figcaption>
                    </figure>
                </div>
                <!-- END: Bells and Whistles - Additional Visual Explorations -->


                <!-- Bells and Whistles - Exploration (text justification) -->
                <div class="mt-6 p-4 bg-slate-900 rounded-lg border border-slate-700">
                    <h4 class="text-xl font-medium text-accent mb-2">Bells and Whistles: Comments</h4>
                    <p class="text-sm">I think the color-color one shows most detail.</p>
                </div>
            </div>

        </section>
        
    </main>

    <footer class="bg-primary p-4 text-center text-xs text-slate-500">
        &copy; 2024 Image Processing Project | Built with HTML & Tailwind CSS
    </footer>

</body>
</html>
